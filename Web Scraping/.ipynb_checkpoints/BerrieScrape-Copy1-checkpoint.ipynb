{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0484a7ef",
   "metadata": {},
   "source": [
    "## Nederland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b85aaa",
   "metadata": {},
   "source": [
    "### Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a45ddcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to Berrie.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.aldi.nl/zoeken.html?query=noten&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/producten/chips-noten/noten-zaden-en-pitten.html\",\n",
    "    \"https://www.aldi.nl/producten/chips-noten/zoutjes.html\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=pitten&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=cashew&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=trader%20joe%20amandelen%20walnoten&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=trader%20joe%20pinda&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=dry%20roasted&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rozijnen%20&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=macadamia&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=time4choco&searchCategory=Submitted%20Search&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_nl_nl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Create an empty list to store all product details\n",
    "all_products = []\n",
    "\n",
    "# Loop over the list of URLs\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    # Retrieve the elements after the wait\n",
    "    articles = driver.find_elements(By.CLASS_NAME, \"mod-article-tile--default\")\n",
    "\n",
    "    # Extract details for each article on the page\n",
    "    for article in articles:\n",
    "        # Use BeautifulSoup to parse the individual article's HTML\n",
    "        soup = BeautifulSoup(article.get_attribute('outerHTML'), \"html.parser\")\n",
    "\n",
    "        title = soup.find('span', class_='mod-article-tile__title').get_text(strip=True) if soup.find('span', class_='mod-article-tile__title') else 'Title not found'\n",
    "        promo_price_element = soup.find('s', class_='price__previous')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'Promo price not found'\n",
    "        current_price_element = soup.find('span', class_='price__wrapper')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "        weight = soup.find('span', class_='price__unit').get_text(strip=True) if soup.find('span', class_='price__unit') else 'Weight not found'\n",
    "\n",
    "        all_products.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": current_price,\n",
    "            \"Promo Price\": promo_price,\n",
    "            \"Weight\": weight,\n",
    "            \"Country\": \"NL\",\n",
    "        \"Store\": \"Aldi\"\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(all_products)\n",
    "\n",
    "# Add a timestamp column\n",
    "df[\"Timestamp\"] = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Save to Excel file\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683471e",
   "metadata": {},
   "source": [
    "## Duitsland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b25a7d",
   "metadata": {},
   "source": [
    "### Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2405a971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to Berrie.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?query=asiatisce%20snack&searchCategory=Submitted%20Search&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?query=kerne&searchCategory=Submitted%20Search&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi-nord.de/sortiment/snacks-suessigkeiten/nuesse-trockenfruechte.html\",\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?query=trader%20joe%20n%C3%BCsse&searchCategory=Submitted%20Search&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&configure%5BclickAnalytics%5D=true\",\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?query=trader%20joe%20mix&searchCategory=Submitted%20Search\",\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?query=schoko%20rosinen&searchCategory=Submitted%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi-nord.de/suchergebnisse.html?searchCategory=Submitted%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_de_de_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&query=choceur%20peanuts\"\n",
    "]\n",
    "\n",
    "# Create an empty list to store all product details\n",
    "all_products = []\n",
    "\n",
    "# Loop over the list of URLs\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the articles to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"mod-article-tile--default\")))\n",
    "\n",
    "    # Retrieve the elements after the wait\n",
    "    articles = driver.find_elements(By.CLASS_NAME, \"mod-article-tile--default\")\n",
    "\n",
    "    # Extract details for each article on the page\n",
    "    for article in articles:\n",
    "        # Use BeautifulSoup to parse the individual article's HTML\n",
    "        soup = BeautifulSoup(article.get_attribute('outerHTML'), \"html.parser\")\n",
    "\n",
    "        title = soup.find('span', class_='mod-article-tile__title').get_text(strip=True) if soup.find('span', class_='mod-article-tile__title') else 'Title not found'\n",
    "        promo_price_element = soup.find('s', class_='price__previous')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'Promo price not found'\n",
    "        current_price_element = soup.find('span', class_='price__wrapper')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "        weight = soup.find('span', class_='price__unit').get_text(strip=True) if soup.find('span', class_='price__unit') else 'Weight not found'\n",
    "\n",
    "        all_products.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": current_price,\n",
    "            \"Promo Price\": promo_price,\n",
    "            \"Weight\": weight,\n",
    "            \"Country\": \"DE\",\n",
    "        \"Store\": \"Aldi\"\n",
    "        })\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Convert the list of products to a pandas DataFrame\n",
    "df = pd.DataFrame(all_products)\n",
    "\n",
    "# Add the timestamp column to the DataFrame\n",
    "df[\"Timestamp\"] = timestamp\n",
    "\n",
    "# Save to Excel (Append if file exists)\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "if os.path.exists(excel_filename):\n",
    "    # Load the existing Excel file and append the new data\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    updated_df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "else:\n",
    "    # If the file doesn't exist, create a new one\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db465ea9-b417-4a27-b041-e1e1218493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    ", options=chrome_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be98f2de",
   "metadata": {},
   "source": [
    "### Globus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16487966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pages: 7\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Data has been successfully saved to Berrie.xlsx\n",
      "Scraping process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime  # Importing datetime module\n",
    "import pandas as pd  # Importing pandas for Excel file saving\n",
    "import os  # Importing os to check if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "url_list = [\n",
    "    \"https://produkte.globus.de/bobenheim-roxheim/search?query=jeden+tag+kern\",\n",
    "    \"https://produkte.globus.de/bobenheim-roxheim/search?p=1&query=jeden%20tag%20n%C3%BCsse\",\n",
    "    \"https://produkte.globus.de/bobenheim-roxheim/search?p=2&query=jeden%20tag%20n%C3%BCsse\",\n",
    "    \"https://produkte.globus.de/bobenheim-roxheim/search?query=jeden+tag+schokolierte\"\n",
    "]\n",
    "\n",
    "# Get the current timestamp for CSV file\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Create an empty list to store all product details\n",
    "all_products = []\n",
    "\n",
    "# Loop over each URL\n",
    "for page_url in url_list:\n",
    "    print(f\"Scraping URL: {page_url}...\")\n",
    "\n",
    "    # Open the current URL\n",
    "    driver.get(page_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Get the page source and parse it with BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Loop through all product cards and extract data\n",
    "    for product_card in soup.find_all(\"div\", class_=\"product-info\"):\n",
    "        # Extract product title\n",
    "        title_tag = product_card.find(\"a\", class_=\"product-image-link product-name\")\n",
    "        title = title_tag.get(\"title\").strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # Extract price\n",
    "        price_div = product_card.find(\"div\", class_=\"unit-price js-unit-price\")\n",
    "        price = price_div.get(\"data-value\") if price_div and price_div.has_attr(\"data-value\") else \"Price not found\"\n",
    "\n",
    "        # Extract weight\n",
    "        weight_div = product_card.find(\"div\", class_=\"price-unit-content\")\n",
    "        weight = weight_div.text.strip() if weight_div else \"Weight not found\"\n",
    "\n",
    "        # Extract promo price\n",
    "        promo_price = \"Promo price not found\"  # Default value in case promo price is not found\n",
    "        promo_price_div = product_card.find(\"div\", class_=\"product-price-globus-discount\")\n",
    "        if promo_price_div:\n",
    "            promo_price_element = promo_price_div.find(\"div\", class_=\"unit-price js-unit-price discount-price\")\n",
    "            if promo_price_element:\n",
    "                promo_price = promo_price_element.text.strip()\n",
    "\n",
    "        # Append the product data to the list\n",
    "        all_products.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Promo Price\": promo_price,\n",
    "            \"Weight\": weight,\n",
    "            \"Country\": \"DE\",\n",
    "            \"Store\": \"Globus\",\n",
    "            \"Timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "# Convert the list of products to a pandas DataFrame\n",
    "df = pd.DataFrame(all_products)\n",
    "\n",
    "# Append to Excel file\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "if os.path.exists(excel_filename):\n",
    "    # If the file exists, load the existing file and append the new data\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    updated_df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "else:\n",
    "    # If the file doesn't exist, create a new one\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Close the driver after extracting data\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping process completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0f9f2",
   "metadata": {},
   "source": [
    "## Frankrijk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7e262",
   "metadata": {},
   "source": [
    "### Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a308e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to Berrie.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import os\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.aldi.fr/produits/epicerie-salee/biscuit-aperitif-chips.html\",\n",
    "    \"https://www.aldi.fr/recherche.html?query=trader%20joe&searchCategory=Submitted%20Search\",\n",
    "    \"https://www.aldi.fr/recherche.html?query=Pignons&searchCategory=Submitted%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_fr_fr_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_fr_fr_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_fr_fr_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_fr_fr_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_fr_fr_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_fr_fr_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_fr_fr_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_fr_fr_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi.fr/recherche.html?query=isaura%20choco%20peanut&searchCategory=Submitted%20Search\"\n",
    "]\n",
    "\n",
    "# Create an empty list to store all product details\n",
    "all_products = []\n",
    "\n",
    "# Loop over the list of URLs\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the articles to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"mod-article-tile--default\")))\n",
    "\n",
    "    # Retrieve the elements after the wait\n",
    "    articles = driver.find_elements(By.CLASS_NAME, \"mod-article-tile--default\")\n",
    "\n",
    "    # Extract details for each article on the page\n",
    "    for article in articles:\n",
    "        # Use BeautifulSoup to parse the individual article's HTML\n",
    "        soup = BeautifulSoup(article.get_attribute('outerHTML'), \"html.parser\")\n",
    "\n",
    "        title = soup.find('span', class_='mod-article-tile__title').get_text(strip=True) if soup.find('span', class_='mod-article-tile__title') else 'Title not found'\n",
    "        promo_price_element = soup.find('s', class_='price__previous')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'Promo price not found'\n",
    "        current_price_element = soup.find('span', class_='price__wrapper')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "        weight = soup.find('span', class_='price__unit').get_text(strip=True) if soup.find('span', class_='price__unit') else 'Weight not found'\n",
    "\n",
    "        all_products.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": current_price,\n",
    "            \"Promo Price\": promo_price,\n",
    "            \"Weight\": weight,\n",
    "            \"Country\": \"FR\",\n",
    "        \"Store\": \"Aldi\"\n",
    "        })\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(all_products)\n",
    "\n",
    "# Add a timestamp column\n",
    "df[\"Timestamp\"] = timestamp\n",
    "\n",
    "\n",
    "# Append to Excel file\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "if os.path.exists(excel_filename):\n",
    "    # If the file exists, load the existing file and append the new data\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "    updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "    updated_df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "else:\n",
    "    # If the file doesn't exist, create a new one\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ca96a",
   "metadata": {},
   "source": [
    "### Carrefour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ddda758",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n\tGetHandleVerifier [0x003FFD53+23747]\n\t(No symbol) [0x00387D54]\n\t(No symbol) [0x0025BE53]\n\t(No symbol) [0x0023D91B]\n\t(No symbol) [0x002C7EFF]\n\t(No symbol) [0x002DAD49]\n\t(No symbol) [0x002C1B96]\n\t(No symbol) [0x00293F3C]\n\t(No symbol) [0x00294EBD]\n\tGetHandleVerifier [0x006DAC73+3017699]\n\tGetHandleVerifier [0x006EB93B+3086507]\n\tGetHandleVerifier [0x006E40F2+3055714]\n\tGetHandleVerifier [0x00495AF0+637536]\n\t(No symbol) [0x00390A5D]\n\t(No symbol) [0x0038DA28]\n\t(No symbol) [0x0038DBC5]\n\t(No symbol) [0x003807F0]\n\tBaseThreadInitThunk [0x755A5D49+25]\n\tRtlInitializeExceptionChain [0x7731CEBB+107]\n\tRtlGetAppContainerNamedObjectPath [0x7731CE41+561]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Open the URL\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Handle cookie consent\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;66;03m# Wait for the cookie settings button to appear\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:393\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n\tGetHandleVerifier [0x003FFD53+23747]\n\t(No symbol) [0x00387D54]\n\t(No symbol) [0x0025BE53]\n\t(No symbol) [0x0023D91B]\n\t(No symbol) [0x002C7EFF]\n\t(No symbol) [0x002DAD49]\n\t(No symbol) [0x002C1B96]\n\t(No symbol) [0x00293F3C]\n\t(No symbol) [0x00294EBD]\n\tGetHandleVerifier [0x006DAC73+3017699]\n\tGetHandleVerifier [0x006EB93B+3086507]\n\tGetHandleVerifier [0x006E40F2+3055714]\n\tGetHandleVerifier [0x00495AF0+637536]\n\t(No symbol) [0x00390A5D]\n\t(No symbol) [0x0038DA28]\n\t(No symbol) [0x0038DBC5]\n\t(No symbol) [0x003807F0]\n\tBaseThreadInitThunk [0x755A5D49+25]\n\tRtlInitializeExceptionChain [0x7731CEBB+107]\n\tRtlGetAppContainerNamedObjectPath [0x7731CE41+561]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "options = Options()\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.carrefour.fr/s?filters%5Bfacet_marque%5D%5B0%5D=CARREFOUR&q=melange&noRedirect=1&userIsPro=0&page=1\",\n",
    "    \"https://www.carrefour.fr/r/epicerie-sucree/sucres-farines-coulis-et-preparation-gateaux/aide-a-la-patisserie/fruits-secs-fruits-confits?filters%5Bfacet_marque%5D%5B0%5D=CARREFOUR&noRedirect=0&userIsPro=0\",\n",
    "    \"https://www.carrefour.fr/r/epicerie-sucree/chocolats-et-bonbons/confiseries-chocolatees/billes-et-bonbons-au-chocolat?filters%5Bfacet_marque%5D%5B0%5D=CARREFOUR&noRedirect=0&userIsPro=0\"\n",
    "]\n",
    "\n",
    "# List to store product information\n",
    "all_products = []\n",
    "\n",
    "for url in urls:\n",
    "    # Open the URL\n",
    "    time.sleep(2)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Handle cookie consent\n",
    "    try:\n",
    "        # Wait for the cookie settings button to appear\n",
    "        param_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.ID, \"onetrust-pc-btn-handler\")))\n",
    "        param_button.click()\n",
    "\n",
    "        # Wait for and click the \"refuse all\" button\n",
    "        confirm_button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CLASS_NAME, \"ot-pc-refuse-all-handler\")))\n",
    "        confirm_button.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Cookie consent handling failed\")\n",
    "\n",
    "    # Parse page source with BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product details\n",
    "    for product_pod in soup.find_all(\"div\", class_=\"main-layout__info-zone\"):\n",
    "        # Extract title\n",
    "        title_tag = product_pod.find(\"a\", class_=\"product-card-title\")\n",
    "        title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # Extract weight\n",
    "        weight_tag = product_pod.find(\"p\", class_=\"pl-text--size-m\")\n",
    "        weight = weight_tag.text.strip() if weight_tag else \"Weight not found\"\n",
    "\n",
    "        # Extract current price (main price)\n",
    "        price_main_tag = product_pod.find(\"div\", class_=\"product-price__amount--main\")\n",
    "        if price_main_tag:\n",
    "            price_main_parts = price_main_tag.find_all(\"p\", class_=\"product-price__content\")\n",
    "            if len(price_main_parts) >= 2:\n",
    "                current_price = f\"{price_main_parts[0].text.strip()}{price_main_parts[1].text.strip()} €\"\n",
    "            else:\n",
    "                current_price = \"Price not found\"\n",
    "        else:\n",
    "            current_price = \"Price not found\"\n",
    "\n",
    "        # Extract promotional price\n",
    "        promo_price_tag = product_pod.find(\"div\", class_=\"product-price__amount--old\")\n",
    "        if promo_price_tag:\n",
    "            promo_price_parts = promo_price_tag.find_all(\"p\", class_=\"product-price__content\")\n",
    "            if len(promo_price_parts) >= 2:\n",
    "                promo_price = f\"{promo_price_parts[0].text.strip()},{promo_price_parts[1].text.strip()} €\"\n",
    "            else:\n",
    "                promo_price = \"Promo price not found\"\n",
    "        else:\n",
    "            promo_price = \"Promo price not found\"\n",
    "\n",
    "        # Add static values\n",
    "        Country = \"FR\"\n",
    "        Store = \"Carrefour\"\n",
    "\n",
    "        # Append extracted information to the list\n",
    "        all_products.append((title, current_price, promo_price, weight, Country, Store))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Prepare the data for saving\n",
    "df = pd.DataFrame(all_products, columns=[\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Country\", \"Store\"])\n",
    "\n",
    "# Add timestamp to the DataFrame\n",
    "df[\"Timestamp\"] = timestamp\n",
    "\n",
    "# Excel file name\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "# Check if the Excel file exists\n",
    "if os.path.exists(excel_filename):\n",
    "    # Read the existing data from the Excel file\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the combined data back to the same sheet\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='w') as writer:\n",
    "        combined_df.to_excel(writer, index=False)\n",
    "else:\n",
    "    # If the file doesn't exist, save the new data as a new Excel file\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7dc72",
   "metadata": {},
   "source": [
    "## Polen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2a03e",
   "metadata": {},
   "source": [
    "### Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3de85769-aa11-43e7-8222-7ff42973cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to Berrie.xlsx\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.aldi.pl/szukaj.html?query=orzechy%20trader&searchCategory=Suggested%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi.pl/szukaj.html?query=asia&searchCategory=Suggested%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi.pl/nasze-produkty/przekaski/pestki--nasiona--ziarna.html\",\n",
    "    \"https://www.aldi.pl/szukaj.html?query=trader%20joe%27s%20&searchCategory=Suggested%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi.pl/szukaj.html?query=orzeszki%20trader&searchCategory=Suggested%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\",\n",
    "    \"https://www.aldi.pl/szukaj.html?query=rodzynki&searchCategory=Suggested%20Search\",\n",
    "    \"https://www.aldi.pl/szukaj.html?query=Orzechy%20laskowe%2FMigda%C5%82y%20w%20czekoladzie%20mlecznej&searchCategory=Submitted%20Search&configure%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_offers%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_assortment%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_recipes%5D%5Bconfigure%5D%5BhitsPerPage%5D=12&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BclickAnalytics%5D=true&indices%5Bprod_pl_pl_content%5D%5Bconfigure%5D%5BhitsPerPage%5D=12\"\n",
    "]\n",
    "\n",
    "# Create an empty list to store all product details\n",
    "all_products = []\n",
    "\n",
    "# Loop over the list of URLs\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the articles to load\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"mod-article-tile--default\")))\n",
    "\n",
    "    # Retrieve the elements after the wait\n",
    "    articles = driver.find_elements(By.CLASS_NAME, \"mod-article-tile--default\")\n",
    "\n",
    "    # Extract details for each article on the page\n",
    "    for article in articles:\n",
    "        # Use BeautifulSoup to parse the individual article's HTML\n",
    "        soup = BeautifulSoup(article.get_attribute('outerHTML'), \"html.parser\")\n",
    "\n",
    "        title = soup.find('span', class_='mod-article-tile__title').get_text(strip=True) if soup.find('span', class_='mod-article-tile__title') else 'Title not found'\n",
    "        promo_price_element = soup.find('s', class_='price__previous')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'Promo price not found'\n",
    "        current_price_element = soup.find('span', class_='price__wrapper')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "        weight = soup.find('span', class_='price__unit').get_text(strip=True) if soup.find('span', class_='price__unit') else 'Weight not found'\n",
    "\n",
    "        Country = \"PL\"\n",
    "        Store = \"Aldi\"\n",
    "\n",
    "        all_products.append((title, current_price, promo_price, weight, Country, Store))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Prepare data for saving to CSV and Excel\n",
    "df = pd.DataFrame(all_products, columns=[\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Country\", \"Store\"])\n",
    "\n",
    "# Add timestamp to the DataFrame\n",
    "df[\"Timestamp\"] = timestamp\n",
    "\n",
    "# Excel file name\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "# Check if the Excel file exists\n",
    "if os.path.exists(excel_filename):\n",
    "    # Read the existing data from the Excel file\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Write back the combined data to the same sheet\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='w') as writer:\n",
    "        combined_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "else:\n",
    "    # If the file doesn't exist, create a new file with the data\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1b9d5",
   "metadata": {},
   "source": [
    "### Biedronka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfaec13d-cb53-4bd8-bea2-f1d6540cb3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wweijs\\AppData\\Local\\Temp\\ipykernel_23464\\2990789472.py:67: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  integer_part = price_main_tag.find(text=True, recursive=False).strip() if price_main_tag else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookie consent not found for URL: https://zakupy.biedronka.pl/artykuly-spozywcze/przekaski/bakalie/ or took too long to load\n",
      "Cookie consent not found for URL: https://zakupy.biedronka.pl/search?q=Magnetic+w+czekoladzie or took too long to load\n",
      "Cookie consent not found for URL: https://zakupy.biedronka.pl/search?q=Wawel+%C5%9Aliwki+w+czekoladzie+180g or took too long to load\n",
      "Cookie consent not found for URL: https://zakupy.biedronka.pl/search?q=Baitz+Milk+Cookie+Balls+Koekjes+in+Melkchocolade+75+g or took too long to load\n",
      "Data has been successfully saved to Berrie.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://zakupy.biedronka.pl/artykuly-spozywcze/przekaski/orzeszki/\",\n",
    "    \"https://zakupy.biedronka.pl/artykuly-spozywcze/przekaski/bakalie/\",\n",
    "    \"https://zakupy.biedronka.pl/search?q=Magnetic+w+czekoladzie\",\n",
    "    \"https://zakupy.biedronka.pl/search?q=Wawel+%C5%9Aliwki+w+czekoladzie+180g\",\n",
    "    \"https://zakupy.biedronka.pl/search?q=Baitz+Milk+Cookie+Balls+Koekjes+in+Melkchocolade+75+g\"\n",
    "]\n",
    "\n",
    "# List to store all product information across multiple pages\n",
    "all_products = []\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "\n",
    "    try:\n",
    "        # Wait for the cookie consent button to be clickable (increased timeout)\n",
    "        param_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.ID, \"onetrust-pc-btn-handler\")))\n",
    "        param_button.click()\n",
    "\n",
    "        # Wait for and click the button to confirm cookie consent\n",
    "        confirm_button = WebDriverWait(driver, 3).until(EC.element_to_be_clickable((By.CLASS_NAME, \"ot-pc-refuse-all-handler\")))\n",
    "        confirm_button.click()\n",
    "    except TimeoutException:\n",
    "        print(f\"Cookie consent not found for URL: {url} or took too long to load\")\n",
    "\n",
    "    # Parse page source with BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product information for the current page\n",
    "    for product_pod in soup.find_all(\"div\", class_=\"product-tile js-product-tile\"):\n",
    "        # Extract title\n",
    "        title_tag = product_pod.find(\"div\", class_=\"product-tile__name product-tile__name--overflow\")\n",
    "        title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # Extract weight (only the weight value, e.g., \"0.2kg\")\n",
    "        weight_tag = product_pod.find(\"div\", class_=\"packaging-details\")\n",
    "        if weight_tag:\n",
    "            weight = weight_tag.contents[0].strip()  # Get the first part before the <span> tag\n",
    "        else:\n",
    "            weight = \"Weight not found\"\n",
    "        \n",
    "        # Extract current price (main price)\n",
    "        price_main_tag = product_pod.find(\"div\", class_=\"price-tile__sales\")\n",
    "        if price_main_tag:\n",
    "            # Extract the integer part of the price\n",
    "            integer_part = price_main_tag.find(text=True, recursive=False).strip() if price_main_tag else None\n",
    "            decimal_part = price_main_tag.find(\"span\", class_=\"price-tile__decimal\")\n",
    "            if integer_part and decimal_part:\n",
    "                # Combine integer and decimal parts into one properly formatted price\n",
    "                raw_price = f\"{integer_part.strip()}{decimal_part.text.strip()}\"  # Combine without formatting\n",
    "                if len(raw_price) > 2:\n",
    "                    current_price = f\"{raw_price[:-2]}.{raw_price[-2:]}\"  # Insert decimal point two digits from the end\n",
    "                else:\n",
    "                    current_price = f\"0,{raw_price}\"  # Handle cases where price is less than 1 zł\n",
    "            else:\n",
    "                current_price = \"Price not found\"\n",
    "        else:\n",
    "            current_price = \"Price not found\"\n",
    "\n",
    "        # Remove any extra spaces (just in case)\n",
    "        current_price = current_price.replace(\" \", \"\").strip()\n",
    "\n",
    "        # Extract promo price if available\n",
    "        promo_price_tag = product_pod.find(\"div\", class_=\"product-tile-prices__regular\")\n",
    "        if promo_price_tag:\n",
    "            promo_price = promo_price_tag.find(\"span\", class_=\"product-tile-prices__amount\")\n",
    "            if promo_price:\n",
    "                promo_price = promo_price.text.strip()\n",
    "            else:\n",
    "                promo_price = \"Promo Price not found\"\n",
    "        else:\n",
    "            promo_price = \"Promo Price not found\"\n",
    "\n",
    "        Country = \"PL\"\n",
    "        Store = \"Biedronka\"\n",
    "\n",
    "        # Append extracted information to the list\n",
    "        all_products.append((title, current_price, promo_price, weight, Country, Store))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Prepare the data for saving\n",
    "df = pd.DataFrame(all_products, columns=[\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Country\", \"Store\"])\n",
    "\n",
    "# Add timestamp to the DataFrame\n",
    "df[\"Timestamp\"] = timestamp\n",
    "\n",
    "# Excel file name\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "# Check if the Excel file exists\n",
    "if os.path.exists(excel_filename):\n",
    "    # Read the existing data from the Excel file\n",
    "    existing_df = pd.read_excel(excel_filename, engine='openpyxl')\n",
    "\n",
    "    # Append the new data to the existing data\n",
    "    combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the combined data back to the same sheet\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='w') as writer:\n",
    "        combined_df.to_excel(writer, index=False)\n",
    "else:\n",
    "    # If the file doesn't exist, save the new data as a new Excel file\n",
    "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Data has been successfully saved to {excel_filename}\")\n",
    "\n",
    "# Quit the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63e324-e65b-4546-ad17-58b1b3dae0bb",
   "metadata": {},
   "source": [
    "### Albert Heijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "810480ec-53c0-4932-8aef-91828210288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to a new sheet in the existing workbook.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re  # For regular expressions\n",
    "from datetime import datetime  # For timestamps\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from openpyxl import load_workbook  # For appending to existing Excel file\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Target URL\n",
    "url = \"https://www.ah.nl/producten/chips-noten-toast-popcorn/noten?merk=AH&page=6\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Accept cookies (specific to the website)\n",
    "accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"decline-cookies\")))\n",
    "accept_button.click()\n",
    "\n",
    "# Get page source and parse with BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# List to store the extracted product information\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract the price from the aria-label of the sr-only span\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    if price_span:\n",
    "        # Use regular expression to extract the numeric price (e.g., 1.99)\n",
    "        match = re.search(r'[\\d]+[.,][\\d]+', price_span.get('aria-label'))\n",
    "        price = match.group() if match else 'Price not found'\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "        \n",
    "    # Extract the promo price (if available)\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            match_promo_price = re.search(r'[\\d]+[.,][\\d]+', promo_price_span_inner.get('aria-label'))\n",
    "            promo_price = match_promo_price.group() if match_promo_price else 'Promo price not found'\n",
    "        else:\n",
    "            promo_price = 'Promo price not found'\n",
    "    else:\n",
    "        promo_price = 'Promo price not found'\n",
    "\n",
    "    # Extract the product title\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'Title not found'\n",
    "    \n",
    "    # Extract the weight\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    # Append data to products list\n",
    "    products.append({\n",
    "        \"Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Promo Price\": promo_price,\n",
    "        \"Weight\": weight,\n",
    "        \"Country\": \"NL\",\n",
    "        \"Store\": \"AH\"\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the products list\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# Add a timestamp column\n",
    "df[\"Timestamp\"] = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Define Excel filename\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "# Check if the file already exists\n",
    "try:\n",
    "    # Try to open the existing workbook and append the new data to a new sheet\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='a') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=f\"AH\")\n",
    "    print(\"Data has been successfully saved to a new sheet in the existing workbook.\")\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist, create a new workbook and save the data\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False)\n",
    "    print(\"New Excel file created and data saved.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96530dbe-da1a-484c-b6ab-1477c00e6d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully appended to the existing sheet.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re  # For regular expressions\n",
    "from datetime import datetime  # For timestamps\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from openpyxl import load_workbook  # For handling existing Excel files\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Target URL\n",
    "url = \"https://www.ah.nl/producten/snoep-chocolade-koek/chocolade/chocoladesnoepjes?merk=AH&kenmerk=prijsfavoriet\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Accept cookies (specific to the website)\n",
    "accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"decline-cookies\")))\n",
    "accept_button.click()\n",
    "\n",
    "# Get page source and parse with BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# List to store the extracted product information\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract the price from the aria-label of the sr-only span\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    if price_span:\n",
    "        # Use regular expression to extract the numeric price (e.g., 1.99)\n",
    "        match = re.search(r'[\\d]+[.,][\\d]+', price_span.get('aria-label'))\n",
    "        price = match.group() if match else 'Price not found'\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "        \n",
    "    # Extract the promo price (if available)\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            match_promo_price = re.search(r'[\\d]+[.,][\\d]+', promo_price_span_inner.get('aria-label'))\n",
    "            promo_price = match_promo_price.group() if match_promo_price else 'Promo price not found'\n",
    "        else:\n",
    "            promo_price = 'Promo price not found'\n",
    "    else:\n",
    "        promo_price = 'Promo price not found'\n",
    "\n",
    "    # Extract the product title\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'Title not found'\n",
    "    \n",
    "    # Extract the weight\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    # Append data to products list\n",
    "    products.append({\n",
    "        \"Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Promo Price\": promo_price,\n",
    "        \"Weight\": weight,\n",
    "        \"Country\": \"NL\",\n",
    "        \"Store\": \"AH\"\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the products list\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# Add a timestamp column\n",
    "df[\"Timestamp\"] = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Define Excel filename\n",
    "excel_filename = 'Berrie.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing workbook\n",
    "    book = load_workbook(excel_filename)\n",
    "    \n",
    "    # Check if sheet exists\n",
    "    if \"AH\" in book.sheetnames:\n",
    "        # Load existing sheet into a DataFrame\n",
    "        existing_data = pd.read_excel(excel_filename, sheet_name=\"AH\")\n",
    "        \n",
    "        # Concatenate existing and new data\n",
    "        combined_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "    else:\n",
    "        # If sheet doesn't exist, just use new data\n",
    "        combined_data = df\n",
    "    \n",
    "    # Write the updated data back to the same sheet\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        combined_data.to_excel(writer, index=False, sheet_name=\"AH\")\n",
    "    \n",
    "    print(\"Data successfully appended to the existing sheet.\")\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist, create a new workbook and save the data\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name=\"AH\")\n",
    "    print(\"New Excel file created and data saved.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
