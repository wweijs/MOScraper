{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db635d48",
   "metadata": {},
   "source": [
    "# Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bdf69a-bddc-4674-9473-8f5d0ce43d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: cannot connect to chrome at 127.0.0.1:65123\nfrom session not created: This version of ChromeDriver only supports Chrome version 138\nCurrent browser version is 141.0.7390.56\nStacktrace:\n\tGetHandleVerifier [0x0x10cba83+63395]\n\tGetHandleVerifier [0x0x10cbac4+63460]\n\t(No symbol) [0x0xf12113]\n\t(No symbol) [0x0xf4bf0b]\n\t(No symbol) [0x0xf4af29]\n\t(No symbol) [0x0xf4128f]\n\t(No symbol) [0x0xf410c6]\n\t(No symbol) [0x0xf8ae57]\n\t(No symbol) [0x0xf8a74a]\n\t(No symbol) [0x0xf7f1a6]\n\t(No symbol) [0x0xf4e7b2]\n\t(No symbol) [0x0xf4f654]\n\tGetHandleVerifier [0x0x1348883+2672035]\n\tGetHandleVerifier [0x0x1343cba+2652634]\n\tGetHandleVerifier [0x0x10f2bca+223466]\n\tGetHandleVerifier [0x0x10e2cb8+158168]\n\tGetHandleVerifier [0x0x10e978d+185517]\n\tGetHandleVerifier [0x0x10d3b78+96408]\n\tGetHandleVerifier [0x0x10d3d02+96802]\n\tGetHandleVerifier [0x0x10be90a+9770]\n\tBaseThreadInitThunk [0x0x76395d49+25]\n\tRtlInitializeExceptionChain [0x0x77cad6db+107]\n\tRtlGetAppContainerNamedObjectPath [0x0x77cad661+561]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_agent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#options.add_argument(\"--headless\")   # run headless if you don‚Äôt need the browser\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# --- Start driver ---\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m driver \u001b[38;5;241m=\u001b[39m uc\u001b[38;5;241m.\u001b[39mChrome(version_main\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m138\u001b[39m, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# --- URLs to scrape ---\u001b[39;00m\n\u001b[0;32m     30\u001b[0m urls \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.jumbo.com/producten/?searchType=keyword&searchTerms=melkchocolade\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20pinda\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20zoet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\undetected_chromedriver\\__init__.py:466\u001b[0m, in \u001b[0;36mChrome.__init__\u001b[1;34m(self, options, user_data_dir, driver_executable_path, browser_executable_path, port, enable_cdp_events, desired_capabilities, advanced_elements, keep_alive, log_level, headless, version_main, patcher_force_close, suppress_welcome, use_subprocess, debug, no_sandbox, user_multi_procs, **kw)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser_pid \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mpid\n\u001b[0;32m    462\u001b[0m service \u001b[38;5;241m=\u001b[39m selenium\u001b[38;5;241m.\u001b[39mwebdriver\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mChromiumService(\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatcher\u001b[38;5;241m.\u001b[39mexecutable_path\n\u001b[0;32m    464\u001b[0m )\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28msuper\u001b[39m(Chrome, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    467\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m    468\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    469\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m    470\u001b[0m )\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_cdp_events:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:66\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(command_executor\u001b[38;5;241m=\u001b[39mexecutor, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:250\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_session(capabilities)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fedcm \u001b[38;5;241m=\u001b[39m FedCM(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_websocket_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\undetected_chromedriver\\__init__.py:724\u001b[0m, in \u001b[0;36mChrome.start_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m capabilities:\n\u001b[0;32m    723\u001b[0m     capabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mto_capabilities()\n\u001b[1;32m--> 724\u001b[0m \u001b[38;5;28msuper\u001b[39m(selenium\u001b[38;5;241m.\u001b[39mwebdriver\u001b[38;5;241m.\u001b[39mchrome\u001b[38;5;241m.\u001b[39mwebdriver\u001b[38;5;241m.\u001b[39mWebDriver, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mstart_session(\n\u001b[0;32m    725\u001b[0m     capabilities\n\u001b[0;32m    726\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    - A capabilities dict to start the session with.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    341\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[1;32m--> 342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mNEW_SESSION, caps)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: cannot connect to chrome at 127.0.0.1:65123\nfrom session not created: This version of ChromeDriver only supports Chrome version 138\nCurrent browser version is 141.0.7390.56\nStacktrace:\n\tGetHandleVerifier [0x0x10cba83+63395]\n\tGetHandleVerifier [0x0x10cbac4+63460]\n\t(No symbol) [0x0xf12113]\n\t(No symbol) [0x0xf4bf0b]\n\t(No symbol) [0x0xf4af29]\n\t(No symbol) [0x0xf4128f]\n\t(No symbol) [0x0xf410c6]\n\t(No symbol) [0x0xf8ae57]\n\t(No symbol) [0x0xf8a74a]\n\t(No symbol) [0x0xf7f1a6]\n\t(No symbol) [0x0xf4e7b2]\n\t(No symbol) [0x0xf4f654]\n\tGetHandleVerifier [0x0x1348883+2672035]\n\tGetHandleVerifier [0x0x1343cba+2652634]\n\tGetHandleVerifier [0x0x10f2bca+223466]\n\tGetHandleVerifier [0x0x10e2cb8+158168]\n\tGetHandleVerifier [0x0x10e978d+185517]\n\tGetHandleVerifier [0x0x10d3b78+96408]\n\tGetHandleVerifier [0x0x10d3d02+96802]\n\tGetHandleVerifier [0x0x10be90a+9770]\n\tBaseThreadInitThunk [0x0x76395d49+25]\n\tRtlInitializeExceptionChain [0x0x77cad6db+107]\n\tRtlGetAppContainerNamedObjectPath [0x0x77cad661+561]\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# --- Setup User-Agent ---\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# --- Setup Chrome options ---\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "#options.add_argument(\"--headless\")   # run headless if you don‚Äôt need the browser\n",
    "\n",
    "# --- Start driver ---\n",
    "driver = uc.Chrome(version_main=138, options=options)\n",
    "\n",
    "# --- URLs to scrape ---\n",
    "urls = [\n",
    "    \"https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\",\n",
    "    \"https://www.jumbo.com/producten/?searchType=keyword&searchTerms=melkchocolade%20pinda%20zoet\"\n",
    "]\n",
    "\n",
    "# --- Excel setup ---\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# --- Scraping loop ---\n",
    "total_products = 0\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"\\nüîé Scraping: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # --- Handle cookies ---\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        print(\"‚úÖ Cookies rejected\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è No cookies popup found.\")\n",
    "\n",
    "    # --- Wait for product cards ---\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    "        )\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Products not found, skipping URL\")\n",
    "        continue\n",
    "\n",
    "    # --- Parse page with BeautifulSoup ---\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    products = []\n",
    "    for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "        # --- Title ---\n",
    "        title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "        title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # --- Promo Price ---\n",
    "        promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "        promo_price = (\n",
    "            re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "            if promo_price_div and promo_price_div.text\n",
    "            else \"No promo\"\n",
    "        )\n",
    "\n",
    "        # --- Regular Price ---\n",
    "        price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "        price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "        price = (\n",
    "            f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "            if price_whole and price_fractional\n",
    "            else \"Price not found\"\n",
    "        )\n",
    "\n",
    "        # --- Weight ---\n",
    "        subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "        weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "        weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "        # --- Brand (from subtitle if available) ---\n",
    "        brand = subtitle_div.text.strip().split(\"‚Ä¢\")[0] if subtitle_div else \"Non_Branded\"\n",
    "\n",
    "        products.append((title, promo_price, price, weight, brand, \"Jumbo\"))\n",
    "\n",
    "    # --- Save to Excel ---\n",
    "    for product in products:\n",
    "        sheet.append((*product, timestamp))\n",
    "\n",
    "    workbook.save(file_name)\n",
    "    total_products += len(products)\n",
    "    print(f\"‚úÖ Extracted {len(products)} products from this page.\")\n",
    "\n",
    "# --- Finish ---\n",
    "driver.quit()\n",
    "print(f\"\\nüéâ Done! Extracted {total_products} products total and saved to {file_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c329bc",
   "metadata": {},
   "source": [
    "# Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # Importing openpyxl for Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=rotsjes&merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=chocolade%20pinda%27s\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\", \"URL\"])\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Click the \"Weigeren\" button to reject cookies if present\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass  # If the button is not found, continue execution\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Loop through all product articles\n",
    "    for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "        title = article.get('title', 'Title not found')\n",
    "        price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "        price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "        \n",
    "        if price_integer and price_decimals:\n",
    "            price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "        else:\n",
    "            price = 'Price not found'\n",
    "        \n",
    "        previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "        promo_price = previous_price_span.get_text(strip=True) if previous_price_span else 'Promo price not found'\n",
    "        \n",
    "        weight_span = article.find('span', class_='OSFillParent')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Plus\", timestamp])\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b30c",
   "metadata": {},
   "source": [
    "# Dirk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8be82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import openpyxl\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "url = \"https://www.dirk.nl/boodschappen/snacks-snoep/chocolade\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Initial load wait\n",
    "\n",
    "# Function to scroll down\n",
    "def scroll_to_load_more(driver, wait_time=2, scroll_increment=1200, scroll_limit=2):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_limit):\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        time.sleep(wait_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "scroll_to_load_more(driver)\n",
    "\n",
    "# Function to safely click an element\n",
    "def safe_click(xpath):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "        time.sleep(1)\n",
    "        element.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking {xpath}: {e}\")\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", element)  # JavaScript fallback\n",
    "        except:\n",
    "            print(f\"JavaScript click failed for {xpath}\")\n",
    "\n",
    "# Close pop-ups or overlays if present\n",
    "try:\n",
    "    close_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "    )\n",
    "    close_button.click()\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"No pop-ups found.\")\n",
    "\n",
    "# Click filters\n",
    "safe_click(\"//label[contains(text(), 'Overige chocolade & bonbons')]\")\n",
    "time.sleep(3)\n",
    "safe_click(\"//label[contains(text(), '1 de Beste')]\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//article[@data-product-id]\"))\n",
    ")\n",
    "\n",
    "# Parse page content\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product information\n",
    "products = []\n",
    "\n",
    "for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "    title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "    \n",
    "    price_integer = article.find('span', class_='price-large')\n",
    "    price_decimals = article.find('span', class_='price-small')\n",
    "    price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "\n",
    "    promo_price_span = article.find('div', class_='label price-label')\n",
    "    promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "\n",
    "    weight_span = article.find('span', class_='subtitle')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Dirk\"))\n",
    "\n",
    "# Save to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))\n",
    "\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6584ea",
   "metadata": {},
   "source": [
    "#### Dirk Rotsjes & Pinda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.dirk.nl/zoeken/producten/1%20de%20beste%20chocolade%20pinda\",\n",
    "    \"https://www.dirk.nl/zoeken/producten/chocolade%20rotsjes\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # Wait for the page to load\n",
    "\n",
    "    # Scrape the page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product information\n",
    "    for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "        title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "        price_integer = article.find('span', class_='price-large')\n",
    "        price_decimals = article.find('span', class_='price-small')\n",
    "        price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "        promo_price_span = article.find('div', class_='label price-label')\n",
    "        promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "        weight_span = article.find('span', class_='subtitle')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Dirk\", timestamp])\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc77d3",
   "metadata": {},
   "source": [
    "# Vomar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.vomar.nl/zoeken?search=g%27woon%20choco\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Vomar site\n",
    "try:\n",
    "    deny_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonDecline\")))\n",
    "    deny_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('div', class_='col-xs-12 col-md-3 product'):\n",
    "    # Extract the product title from the 'description' class\n",
    "    title = article.find('p', class_='description').get_text(strip=True) if article.find('p', class_='description') else 'Title not found'\n",
    "\n",
    "    # Extract the price from the 'price right' class\n",
    "    price_integer = article.find('span', class_='large')\n",
    "    price_decimals = article.find('span', class_='small')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the promotional price (if applicable, based on previous logic)\n",
    "    promo_price = 'Promo price not found'  # Placeholder since no promo price was in the provided HTML\n",
    "\n",
    "    # Weight extraction can be omitted as there is no weight data in the provided HTML\n",
    "    weight = 'Weight not found'  # Placeholder since no weight was provided\n",
    "\n",
    "    # Store the extracted information as a tuple\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Vomar\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Write product data to Excel\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))  # Write product data with timestamp\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f9f42",
   "metadata": {},
   "source": [
    "# Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49535c4f-ffbd-4bc0-9079-49fe7ca08f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to loop through\n",
    "urls = [\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rotsjes\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=time+4+choco\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=chocolade+pinda\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=peanut\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rozijn\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=pinda\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)  # Load existing file\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Non_Branded\", \"Retailer\", \"Timestamp\"])  # Headers\n",
    "\n",
    "# Loop through the URLs and scrape data\n",
    "for url in urls:\n",
    "    driver.get(url)  # Navigate to the page first\n",
    "\n",
    "    # Wait for the products to load\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-tile__content\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Warning: No products found for {url}\")\n",
    "\n",
    "    # Get the page source after JavaScript renders it\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # List to hold product data\n",
    "    products = []\n",
    "\n",
    "    # Loop through all product tiles\n",
    "    for product in soup.find_all('div', class_='product-tile__content'):\n",
    "        # Extract product title\n",
    "        title_element = product.find('h2', class_='product-tile__content__upper__product-name')\n",
    "        title = title_element.get_text(strip=True) if title_element else 'Title not found'\n",
    "\n",
    "        # Extract current price\n",
    "        current_price_element = product.find('span', class_='tag__label tag__label--price')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "\n",
    "\n",
    "        # Extract promo price (only the number, exclude percentage discount)\n",
    "        promo_price_element = product.find('p', class_='text product-tile__content__lower__wrapper__price-section__discount__striked')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'No promo price'\n",
    "\n",
    "        # Extract weight\n",
    "        weight_container = product.find('div', class_='tag__info')\n",
    "        weight_element = weight_container.find('span', class_='tag__marker') if weight_container else None\n",
    "        weight = weight_element.get_text(strip=True) if weight_element else 'Weight not found'\n",
    "\n",
    "\n",
    "        # Append product data\n",
    "        products.append((title, current_price, promo_price, weight, \"Non_Branded\", \"Aldi\"))\n",
    "\n",
    "    # Add timestamp\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Write product data to Excel\n",
    "    for product in products:\n",
    "        ws.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97c0a7-f3c7-4b60-9065-46a1948ca1dd",
   "metadata": {},
   "source": [
    "# Albert Heijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce407da-05e9-4a1c-8ef2-d22f5677f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=138, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=AH\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265db010-1195-4b2e-a7d4-2464ed967901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=138, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/zoeken?query=ah%20choco%20pinda%27s%20zoet\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b165f71",
   "metadata": {},
   "source": [
    "## M&M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4288",
   "metadata": {},
   "source": [
    "### AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd810bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=138, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=M%26M%27S\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49dbe9",
   "metadata": {},
   "source": [
    "### Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf56446-cf98-496c-aec0-6e924950058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Chrome options\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")  # New headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "\n",
    "# Start undetected Chrome (force version 138 to match your Chrome)\n",
    "driver = uc.Chrome(options=options, version_main=138)\n",
    "\n",
    "# Navigate to the Jumbo products page\n",
    "url = \"https://www.jumbo.com/producten/menms/?searchType=keyword&searchTerms=m%26m\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load and accept cookies\n",
    "try:\n",
    "    accept_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "    )\n",
    "    accept_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    ")\n",
    "\n",
    "# Load page source into BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product data\n",
    "products = []\n",
    "\n",
    "for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "    # Extract product title\n",
    "    title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "    title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "    # Extract promo price\n",
    "    promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "    promo_price = (\n",
    "        re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "        if promo_price_div and promo_price_div.text\n",
    "        else \"Promo price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract price\n",
    "    price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "    price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "    price = (\n",
    "        f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "        if price_whole and price_fractional\n",
    "        else \"Price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract weight\n",
    "    subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "    weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "    weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "    # Append to products list\n",
    "    products.append((title, promo_price, price, weight, \"branded\", \"Jumbo\"))\n",
    "\n",
    "# Write to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Extracted {len(products)} products and saved to {file_name}.\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a2a49",
   "metadata": {},
   "source": [
    "### Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re  # Importing the regular expression module\n",
    "from datetime import datetime  # Importing datetime for timestamp\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=M%26M%27S\"\n",
    "driver.get(url)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Plus site\n",
    "\n",
    "# Wait for the \"Weigeren\" button to be clickable\n",
    "accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\")))\n",
    "accept_button.click()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# List to store the extracted product information\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "    # Extract the product title from the title attribute of the anchor tag\n",
    "    title = article.get('title', 'Title not found')\n",
    "\n",
    "    # Extract the price from the price integers and decimals\n",
    "    price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "    price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the previous (old) price from the price-previous div\n",
    "    previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "    if previous_price_span:\n",
    "        # Extract the old price as text\n",
    "        promo_price = previous_price_span.get_text(strip=True)\n",
    "    else:\n",
    "        promo_price = 'Promo price not found'\n",
    "\n",
    "    # Extract the weight from the 'Per 250 g' span\n",
    "    weight_span = article.find('span', class_='OSFillParent')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    # Store the extracted information as a tuple, including promo price\n",
    "    products.append((title, price, promo_price, weight, \"branded\", \"Plus\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD HH:MM:SS\n",
    "\n",
    "# Write the data to an Excel file\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
