{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db635d48",
   "metadata": {},
   "source": [
    "# Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdf69a-bddc-4674-9473-8f5d0ce43d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Scraping: https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîé Scraping: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# --- Handle cookies ---\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\undetected_chromedriver\\__init__.py:665\u001b[0m, in \u001b[0;36mChrome.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# if self._get_cdc_props():\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;66;03m#     self._hook_remove_cdc_props()\u001b[39;00m\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget(url)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:454\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03m    tab.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    425\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\request.py:81\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     78\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     79\u001b[0m     )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     82\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     83\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\request.py:173\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    171\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    717\u001b[0m     conn,\n\u001b[0;32m    718\u001b[0m     method,\n\u001b[0;32m    719\u001b[0m     url,\n\u001b[0;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 468\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wweijs\\AppData\\Local\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# --- Setup User-Agent ---\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# --- Setup Chrome options ---\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "#options.add_argument(\"--headless\")   # run headless if you don‚Äôt need the browser\n",
    "\n",
    "# --- Start driver ---\n",
    "driver = uc.Chrome(version_main=141, options=options)\n",
    "\n",
    "# --- URLs to scrape ---\n",
    "urls = [\n",
    "    \"https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\",\n",
    "    \"https://www.jumbo.com/producten/?searchType=keyword&searchTerms=melkchocolade%20pinda%20zoet\"\n",
    "]\n",
    "\n",
    "# --- Excel setup ---\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# --- Scraping loop ---\n",
    "total_products = 0\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"\\nüîé Scraping: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # --- Handle cookies ---\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "        print(\"‚úÖ Cookies rejected\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è No cookies popup found.\")\n",
    "\n",
    "    # --- Wait for product cards ---\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    "        )\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Products not found, skipping URL\")\n",
    "        continue\n",
    "\n",
    "    # --- Parse page with BeautifulSoup ---\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    products = []\n",
    "    for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "        # --- Title ---\n",
    "        title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "        title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # --- Promo Price ---\n",
    "        promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "        promo_price = (\n",
    "            re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "            if promo_price_div and promo_price_div.text\n",
    "            else \"No promo\"\n",
    "        )\n",
    "\n",
    "        # --- Regular Price ---\n",
    "        price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "        price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "        price = (\n",
    "            f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "            if price_whole and price_fractional\n",
    "            else \"Price not found\"\n",
    "        )\n",
    "\n",
    "        # --- Weight ---\n",
    "        subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "        weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "        weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "        # --- Brand (from subtitle if available) ---\n",
    "        brand = \"Non_Branded\"\n",
    "\n",
    "        products.append((title, promo_price, price, weight, brand, \"Jumbo\"))\n",
    "\n",
    "    # --- Save to Excel ---\n",
    "    for product in products:\n",
    "        sheet.append((*product, timestamp))\n",
    "\n",
    "    workbook.save(file_name)\n",
    "    total_products += len(products)\n",
    "    print(f\"‚úÖ Extracted {len(products)} products from this page.\")\n",
    "\n",
    "# --- Finish ---\n",
    "driver.quit()\n",
    "print(f\"\\nüéâ Done! Extracted {total_products} products total and saved to {file_name}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c329bc",
   "metadata": {},
   "source": [
    "# Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # Importing openpyxl for Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=rotsjes&merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=chocolade%20pinda%27s\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\", \"URL\"])\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Click the \"Weigeren\" button to reject cookies if present\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass  # If the button is not found, continue execution\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Loop through all product articles\n",
    "    for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "        title = article.get('title', 'Title not found')\n",
    "        price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "        price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "        \n",
    "        if price_integer and price_decimals:\n",
    "            price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "        else:\n",
    "            price = 'Price not found'\n",
    "        \n",
    "        previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "        promo_price = previous_price_span.get_text(strip=True) if previous_price_span else 'Promo price not found'\n",
    "        \n",
    "        weight_span = article.find('span', class_='OSFillParent')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Plus\", timestamp])\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b30c",
   "metadata": {},
   "source": [
    "# Dirk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8be82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pop-ups found.\n",
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import openpyxl\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "url = \"https://www.dirk.nl/boodschappen/snacks-snoep/chocolade\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Initial load wait\n",
    "\n",
    "# Function to scroll down\n",
    "def scroll_to_load_more(driver, wait_time=2, scroll_increment=1200, scroll_limit=2):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_limit):\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        time.sleep(wait_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "scroll_to_load_more(driver)\n",
    "\n",
    "# Function to safely click an element\n",
    "def safe_click(xpath):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "        time.sleep(1)\n",
    "        element.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking {xpath}: {e}\")\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", element)  # JavaScript fallback\n",
    "        except:\n",
    "            print(f\"JavaScript click failed for {xpath}\")\n",
    "\n",
    "# Close pop-ups or overlays if present\n",
    "try:\n",
    "    close_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "    )\n",
    "    close_button.click()\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"No pop-ups found.\")\n",
    "\n",
    "# Click filters\n",
    "safe_click(\"//label[contains(text(), 'Overige chocolade & bonbons')]\")\n",
    "time.sleep(3)\n",
    "safe_click(\"//label[contains(text(), '1 de Beste')]\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//article[@data-product-id]\"))\n",
    ")\n",
    "\n",
    "# Parse page content\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product information\n",
    "products = []\n",
    "\n",
    "for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "    title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "    \n",
    "    price_integer = article.find('span', class_='price-large')\n",
    "    price_decimals = article.find('span', class_='price-small')\n",
    "    price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "\n",
    "    promo_price_span = article.find('div', class_='label price-label')\n",
    "    promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "\n",
    "    weight_span = article.find('span', class_='subtitle')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Dirk\"))\n",
    "\n",
    "# Save to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))\n",
    "\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6584ea",
   "metadata": {},
   "source": [
    "#### Dirk Rotsjes & Pinda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf30d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.dirk.nl/zoeken/producten/1%20de%20beste%20chocolade%20pinda\",\n",
    "    \"https://www.dirk.nl/zoeken/producten/pindarots\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # Wait for the page to load\n",
    "\n",
    "    # Scrape the page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product information\n",
    "    for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "        title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "        price_integer = article.find('span', class_='price-large')\n",
    "        price_decimals = article.find('span', class_='price-small')\n",
    "        price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "        promo_price_span = article.find('div', class_='label price-label')\n",
    "        promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "        weight_span = article.find('span', class_='subtitle')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Dirk\", timestamp])\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc77d3",
   "metadata": {},
   "source": [
    "# Vomar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f4f30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.vomar.nl/zoeken?search=g%27woon%20choco\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Vomar site\n",
    "try:\n",
    "    deny_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonDecline\")))\n",
    "    deny_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('div', class_='col-xs-12 col-md-3 product'):\n",
    "    # Extract the product title from the 'description' class\n",
    "    title = article.find('p', class_='description').get_text(strip=True) if article.find('p', class_='description') else 'Title not found'\n",
    "\n",
    "    # Extract the price from the 'price right' class\n",
    "    price_integer = article.find('span', class_='large')\n",
    "    price_decimals = article.find('span', class_='small')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the promotional price (if applicable, based on previous logic)\n",
    "    promo_price = 'Promo price not found'  # Placeholder since no promo price was in the provided HTML\n",
    "\n",
    "    # Weight extraction can be omitted as there is no weight data in the provided HTML\n",
    "    weight = 'Weight not found'  # Placeholder since no weight was provided\n",
    "\n",
    "    # Store the extracted information as a tuple\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Vomar\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Write product data to Excel\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))  # Write product data with timestamp\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f9f42",
   "metadata": {},
   "source": [
    "# Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49535c4f-ffbd-4bc0-9079-49fe7ca08f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No products found for https://www.aldi.nl/zoeken.html?query=time+4+choco\n",
      "Data successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to loop through\n",
    "urls = [\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rotsjes\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=time+4+choco\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=chocolade+pinda\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=peanut\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rozijn\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=pinda\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)  # Load existing file\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Non_Branded\", \"Retailer\", \"Timestamp\"])  # Headers\n",
    "\n",
    "# Loop through the URLs and scrape data\n",
    "for url in urls:\n",
    "    driver.get(url)  # Navigate to the page first\n",
    "\n",
    "    # Wait for the products to load\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-tile__content\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Warning: No products found for {url}\")\n",
    "\n",
    "    # Get the page source after JavaScript renders it\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # List to hold product data\n",
    "    products = []\n",
    "\n",
    "    # Loop through all product tiles\n",
    "    for product in soup.find_all('div', class_='product-tile__content'):\n",
    "        # Extract product title\n",
    "        title_element = product.find('h2', class_='product-tile__content__upper__product-name')\n",
    "        title = title_element.get_text(strip=True) if title_element else 'Title not found'\n",
    "\n",
    "        # Extract current price\n",
    "        current_price_element = product.find('span', class_='tag__label tag__label--price')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "\n",
    "\n",
    "        # Extract promo price (only the number, exclude percentage discount)\n",
    "        promo_price_element = product.find('p', class_='text product-tile__content__lower__wrapper__price-section__discount__striked')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'No promo price'\n",
    "\n",
    "        # Extract weight\n",
    "        weight_container = product.find('div', class_='tag__info')\n",
    "        weight_element = weight_container.find('span', class_='tag__marker') if weight_container else None\n",
    "        weight = weight_element.get_text(strip=True) if weight_element else 'Weight not found'\n",
    "\n",
    "\n",
    "        # Append product data\n",
    "        products.append((title, current_price, promo_price, weight, \"Non_Branded\", \"Aldi\"))\n",
    "\n",
    "    # Add timestamp\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Write product data to Excel\n",
    "    for product in products:\n",
    "        ws.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97c0a7-f3c7-4b60-9065-46a1948ca1dd",
   "metadata": {},
   "source": [
    "# Albert Heijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce407da-05e9-4a1c-8ef2-d22f5677f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=141, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=AH&Merk=ah\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265db010-1195-4b2e-a7d4-2464ed967901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=141, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/zoeken?query=ah%20choco%20pinda%27s%20zoet\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b165f71",
   "metadata": {},
   "source": [
    "## M&M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4288",
   "metadata": {},
   "source": [
    "### AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd810bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(version_main=141, options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=M%26M%27S&Merk=m-en-m-s\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: ‚Ç¨\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', price)  # Verwijder \"Prijs: ‚Ç¨\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: ‚Ç¨\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*‚Ç¨\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"‚úÖ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49dbe9",
   "metadata": {},
   "source": [
    "### Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf56446-cf98-496c-aec0-6e924950058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 19 products and saved to choco.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Chrome options\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")  # New headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "\n",
    "# Start undetected Chrome (force version 138 to match your Chrome)\n",
    "driver = uc.Chrome(options=options, version_main=141)\n",
    "\n",
    "# Navigate to the Jumbo products page\n",
    "url = \"https://www.jumbo.com/producten/menms/?searchType=keyword&searchTerms=m%26m\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load and accept cookies\n",
    "try:\n",
    "    accept_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "    )\n",
    "    accept_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    ")\n",
    "\n",
    "# Load page source into BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product data\n",
    "products = []\n",
    "\n",
    "for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "    # Extract product title\n",
    "    title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "    title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "    # Extract promo price\n",
    "    promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "    promo_price = (\n",
    "        re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "        if promo_price_div and promo_price_div.text\n",
    "        else \"Promo price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract price\n",
    "    price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "    price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "    price = (\n",
    "        f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "        if price_whole and price_fractional\n",
    "        else \"Price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract weight\n",
    "    subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "    weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "    weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "    # Append to products list\n",
    "    products.append((title, promo_price, price, weight, \"branded\", \"Jumbo\"))\n",
    "\n",
    "# Write to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Extracted {len(products)} products and saved to {file_name}.\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a2a49",
   "metadata": {},
   "source": [
    "### Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a4dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re  # Importing the regular expression module\n",
    "from datetime import datetime  # Importing datetime for timestamp\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=M%26M%27S\"\n",
    "driver.get(url)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Plus site\n",
    "\n",
    "# Wait for the \"Weigeren\" button to be clickable\n",
    "accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\")))\n",
    "accept_button.click()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# List to store the extracted product information\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "    # Extract the product title from the title attribute of the anchor tag\n",
    "    title = article.get('title', 'Title not found')\n",
    "\n",
    "    # Extract the price from the price integers and decimals\n",
    "    price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "    price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the previous (old) price from the price-previous div\n",
    "    previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "    if previous_price_span:\n",
    "        # Extract the old price as text\n",
    "        promo_price = previous_price_span.get_text(strip=True)\n",
    "    else:\n",
    "        promo_price = 'Promo price not found'\n",
    "\n",
    "    # Extract the weight from the 'Per 250 g' span\n",
    "    weight_span = article.find('span', class_='OSFillParent')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    # Store the extracted information as a tuple, including promo price\n",
    "    products.append((title, price, promo_price, weight, \"branded\", \"Plus\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD HH:MM:SS\n",
    "\n",
    "# Write the data to an Excel file\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
