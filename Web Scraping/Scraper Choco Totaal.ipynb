{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db635d48",
   "metadata": {},
   "source": [
    "# Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1879290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\n",
      "Extracted 13 products from this page.\n",
      "Scraping: https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=24\n",
      "No accept cookies button found.\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo accept cookies button found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Wait for products to load\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m WebDriverWait(driver, \u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[0;32m     63\u001b[0m     EC\u001b[38;5;241m.\u001b[39mpresence_of_all_elements_located((By\u001b[38;5;241m.\u001b[39mCLASS_NAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjum-card\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load page source into BeautifulSoup\u001b[39;00m\n\u001b[0;32m     67\u001b[0m html \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mpage_source\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:146\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of Jumbo product search URLs\n",
    "urls = [\n",
    "    \"https://www.jumbo.com/producten/koek,-snoep,-chocolade-en-chips/chocolade/chocoladepindas,-snoepjes/jumbo/?offSet=0\",\n",
    "    \"https://www.jumbo.com/producten/?searchType=keyword&searchTerms=melkchocolade%20pinda%20zoet\"\n",
    "]\n",
    "\n",
    "# Prepare Excel file\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write header row\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Loop through each URL\n",
    "total_products = 0\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"Scraping: {url}\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # Accept cookies if present\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        print(\"No accept cookies button found.\")\n",
    "\n",
    "    # Wait for products to load\n",
    "    WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    "    )\n",
    "\n",
    "    # Load page source into BeautifulSoup\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product data\n",
    "    products = []\n",
    "\n",
    "    for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "        # Extract product title\n",
    "        title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "        title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "        # Extract promo price\n",
    "        promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "        promo_price = (\n",
    "            re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "            if promo_price_div and promo_price_div.text\n",
    "            else \"Promo price not found\"\n",
    "        )\n",
    "\n",
    "        # Extract price\n",
    "        price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "        price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "        price = (\n",
    "            f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "            if price_whole and price_fractional\n",
    "            else \"Price not found\"\n",
    "        )\n",
    "\n",
    "        # Extract weight\n",
    "        subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "        weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "        weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "        # Append to products list\n",
    "        products.append((title, promo_price, price, weight, \"Non_Branded\", \"Jumbo\"))\n",
    "\n",
    "    # Write data to the Excel sheet\n",
    "    for product in products:\n",
    "        sheet.append((*product, timestamp))\n",
    "\n",
    "    total_products += len(products)\n",
    "    print(f\"Extracted {len(products)} products from this page.\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Extracted a total of {total_products} products and saved to {file_name}.\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c329bc",
   "metadata": {},
   "source": [
    "# Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346a7b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # Importing openpyxl for Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=rotsjes&merk=PLUS\",\n",
    "    \"https://www.plus.nl/zoekresultaten?SearchTerm=chocolade%20pinda%27s\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\", \"URL\"])\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Click the \"Weigeren\" button to reject cookies if present\n",
    "    try:\n",
    "        accept_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\"))\n",
    "        )\n",
    "        accept_button.click()\n",
    "    except:\n",
    "        pass  # If the button is not found, continue execution\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Loop through all product articles\n",
    "    for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "        title = article.get('title', 'Title not found')\n",
    "        price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "        price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "        \n",
    "        if price_integer and price_decimals:\n",
    "            price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "        else:\n",
    "            price = 'Price not found'\n",
    "        \n",
    "        previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "        promo_price = previous_price_span.get_text(strip=True) if previous_price_span else 'Promo price not found'\n",
    "        \n",
    "        weight_span = article.find('span', class_='OSFillParent')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Get current timestamp\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Plus\", timestamp])\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8b30c",
   "metadata": {},
   "source": [
    "# Dirk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b8be82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pop-ups found.\n",
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import openpyxl\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "url = \"https://www.dirk.nl/boodschappen/snacks-snoep/chocolade\"\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Initial load wait\n",
    "\n",
    "# Function to scroll down\n",
    "def scroll_to_load_more(driver, wait_time=2, scroll_increment=1200, scroll_limit=2):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_limit):\n",
    "        driver.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        time.sleep(wait_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "scroll_to_load_more(driver)\n",
    "\n",
    "# Function to safely click an element\n",
    "def safe_click(xpath):\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "        time.sleep(1)\n",
    "        element.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking {xpath}: {e}\")\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].click();\", element)  # JavaScript fallback\n",
    "        except:\n",
    "            print(f\"JavaScript click failed for {xpath}\")\n",
    "\n",
    "# Close pop-ups or overlays if present\n",
    "try:\n",
    "    close_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept')]\"))\n",
    "    )\n",
    "    close_button.click()\n",
    "    time.sleep(2)\n",
    "except:\n",
    "    print(\"No pop-ups found.\")\n",
    "\n",
    "# Click filters\n",
    "safe_click(\"//label[contains(text(), 'Overige chocolade & bonbons')]\")\n",
    "time.sleep(3)\n",
    "safe_click(\"//label[contains(text(), '1 de Beste')]\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//article[@data-product-id]\"))\n",
    ")\n",
    "\n",
    "# Parse page content\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product information\n",
    "products = []\n",
    "\n",
    "for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "    title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "    \n",
    "    price_integer = article.find('span', class_='price-large')\n",
    "    price_decimals = article.find('span', class_='price-small')\n",
    "    price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "\n",
    "    promo_price_span = article.find('div', class_='label price-label')\n",
    "    promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "\n",
    "    weight_span = article.find('span', class_='subtitle')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Dirk\"))\n",
    "\n",
    "# Save to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))\n",
    "\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6584ea",
   "metadata": {},
   "source": [
    "#### Dirk Rotsjes & Pinda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf30d880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://www.dirk.nl/zoeken/producten/1%20de%20beste%20chocolade%20pinda\",\n",
    "    \"https://www.dirk.nl/zoeken/producten/chocolade%20rotsjes\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Loop over each URL\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # Wait for the page to load\n",
    "\n",
    "    # Scrape the page source\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract product information\n",
    "    for article in soup.find_all('article', attrs={'data-product-id': True}):\n",
    "        title = article.find('p', class_='title').get_text(strip=True) if article.find('p', class_='title') else 'Title not found'\n",
    "        price_integer = article.find('span', class_='price-large')\n",
    "        price_decimals = article.find('span', class_='price-small')\n",
    "        price = f\"{price_integer.get_text(strip=True)},{price_decimals.get_text(strip=True)}\" if price_integer and price_decimals else 'Price not found'\n",
    "        promo_price_span = article.find('div', class_='label price-label')\n",
    "        promo_price = promo_price_span.find('span', class_='regular-price').find('span').get_text(strip=True) if promo_price_span else 'Promo price not found'\n",
    "        weight_span = article.find('span', class_='subtitle')\n",
    "        weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "        \n",
    "        # Write product data to Excel\n",
    "        ws.append([title, price, promo_price, weight, \"Non_Branded\", \"Dirk\", timestamp])\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc77d3",
   "metadata": {},
   "source": [
    "# Vomar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f4f30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.vomar.nl/zoeken?search=g%27woon%20choco\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Vomar site\n",
    "try:\n",
    "    deny_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"CybotCookiebotDialogBodyButtonDecline\")))\n",
    "    deny_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('div', class_='col-xs-12 col-md-3 product'):\n",
    "    # Extract the product title from the 'description' class\n",
    "    title = article.find('p', class_='description').get_text(strip=True) if article.find('p', class_='description') else 'Title not found'\n",
    "\n",
    "    # Extract the price from the 'price right' class\n",
    "    price_integer = article.find('span', class_='large')\n",
    "    price_decimals = article.find('span', class_='small')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the promotional price (if applicable, based on previous logic)\n",
    "    promo_price = 'Promo price not found'  # Placeholder since no promo price was in the provided HTML\n",
    "\n",
    "    # Weight extraction can be omitted as there is no weight data in the provided HTML\n",
    "    weight = 'Weight not found'  # Placeholder since no weight was provided\n",
    "\n",
    "    # Store the extracted information as a tuple\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"Vomar\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    # If the file exists, load it\n",
    "    wb = openpyxl.load_workbook(file_name)\n",
    "    ws = wb.active\n",
    "else:\n",
    "    # If the file does not exist, create a new workbook and worksheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    # Write the headers\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Branded\", \"Retailer\", \"Timestamp\"])\n",
    "\n",
    "# Write product data to Excel\n",
    "for product in products:\n",
    "    ws.append((*product, timestamp))  # Write product data with timestamp\n",
    "\n",
    "# Save the workbook to an Excel file\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f9f42",
   "metadata": {},
   "source": [
    "# Aldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49535c4f-ffbd-4bc0-9079-49fe7ca08f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl  # For Excel file handling\n",
    "import os  # For checking if file exists\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of URLs to loop through\n",
    "urls = [\n",
    "    \"https://www.aldi.nl/zoeken.html?query=rotsjes\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=time+4+choco\",\n",
    "    \"https://www.aldi.nl/zoeken.html?query=chocolade+pinda\"\n",
    "]\n",
    "\n",
    "# Define the file name\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "# Check if the Excel file already exists\n",
    "if os.path.exists(file_name):\n",
    "    wb = openpyxl.load_workbook(file_name)  # Load existing file\n",
    "    ws = wb.active\n",
    "else:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Products\"\n",
    "    ws.append([\"Product Title\", \"Price\", \"Promo Price\", \"Weight\", \"Non_Branded\", \"Retailer\", \"Timestamp\"])  # Headers\n",
    "\n",
    "# Loop through the URLs and scrape data\n",
    "for url in urls:\n",
    "    driver.get(url)  # Navigate to the page first\n",
    "\n",
    "    # Wait for the products to load\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-tile__content\"))\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Warning: No products found for {url}\")\n",
    "\n",
    "    # Get the page source after JavaScript renders it\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # List to hold product data\n",
    "    products = []\n",
    "\n",
    "    # Loop through all product tiles\n",
    "    for product in soup.find_all('div', class_='product-tile__content'):\n",
    "        # Extract product title\n",
    "        title_element = product.find('h2', class_='product-tile__content__upper__product-name')\n",
    "        title = title_element.get_text(strip=True) if title_element else 'Title not found'\n",
    "\n",
    "        # Extract current price\n",
    "        current_price_element = product.find('div', class_='tag__label tag__label--price')\n",
    "        current_price = current_price_element.get_text(strip=True) if current_price_element else 'Price not found'\n",
    "\n",
    "        # Extract promo price (only the number, exclude percentage discount)\n",
    "        promo_price_element = product.find('p', class_='text product-tile__content__lower__wrapper__price-section__discount__striked')\n",
    "        promo_price = promo_price_element.get_text(strip=True) if promo_price_element else 'No promo price'\n",
    "\n",
    "        # Extract weight\n",
    "        weight_element = product.find('p', class_='product-tile__content__lower__wrapper__legal__text')\n",
    "        weight = weight_element.get_text(strip=True) if weight_element else 'Weight not found'\n",
    "\n",
    "        # Append product data\n",
    "        products.append((title, current_price, promo_price, weight, \"Non_Branded\", \"Aldi\"))\n",
    "\n",
    "    # Add timestamp\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Write product data to Excel\n",
    "    for product in products:\n",
    "        ws.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(file_name)\n",
    "\n",
    "print(f\"Data successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97c0a7-f3c7-4b60-9065-46a1948ca1dd",
   "metadata": {},
   "source": [
    "# Albert Heijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce407da-05e9-4a1c-8ef2-d22f5677f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=AH\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: €\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*€\\s*', '', price)  # Verwijder \"Prijs: €\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: €\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*€\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"✅ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265db010-1195-4b2e-a7d4-2464ed967901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/zoeken?query=ah%20choco%20pinda%27s%20zoet\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: €\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*€\\s*', '', price)  # Verwijder \"Prijs: €\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: €\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*€\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Non_Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"✅ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b165f71",
   "metadata": {},
   "source": [
    "## M&M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4288",
   "metadata": {},
   "source": [
    "### AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd810bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data succesvol opgeslagen naar choco.xlsx in blad 'AH_Choco'.\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re  # Importing the regex module\n",
    "\n",
    "# Instellen van User-Agent\n",
    "ua = UserAgent()\n",
    "user_agent = ua.random\n",
    "\n",
    "# Chrome opties configureren\n",
    "options = uc.options.ChromeOptions()\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--disable-features=VizDisplayCompositor\")\n",
    "options.add_argument(f\"user-agent={user_agent}\")\n",
    "\n",
    "\n",
    "# Start de WebDriver met undetected_chromedriver\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# URL die je wilt scrapen\n",
    "url = \"https://www.ah.nl/producten/1854/chocolade-bites?merk=M%26M%27S\"\n",
    "\n",
    "# Ga naar de pagina\n",
    "driver.get(url)\n",
    "\n",
    "# Wacht een paar seconden zodat de pagina volledig laadt\n",
    "time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Verkrijg de HTML van de pagina\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse de HTML met BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Lijst om productdata op te slaan\n",
    "products = []\n",
    "\n",
    "# Loop door alle productartikelen op de pagina\n",
    "for article in soup.find_all('article', class_='product-card-portrait_root__ZiRpZ'):\n",
    "    # Extract prijs\n",
    "    price_span = article.find('span', class_='sr-only')\n",
    "    price = price_span.get('aria-label') if price_span else 'N/A'\n",
    "    \n",
    "    # Verwijder \"Prijs: €\" en extra spaties\n",
    "    if price != 'N/A':\n",
    "        price = re.sub(r'Prijs:\\s*€\\s*', '', price)  # Verwijder \"Prijs: €\"\n",
    "        price = price.strip()  # Verwijder extra spaties rondom de prijs\n",
    "\n",
    "    # Extract promo prijs\n",
    "    promo_price_span = article.find('div', class_='price-amount_highlight__ekL92')\n",
    "    promo_price = \"N/A\"\n",
    "    if promo_price_span:\n",
    "        promo_price_span_inner = promo_price_span.find('span', class_='sr-only')\n",
    "        if promo_price_span_inner:\n",
    "            promo_price = promo_price_span_inner.get('aria-label')\n",
    "\n",
    "    # Verwijder promo prijs \"Prijs: €\" en extra spaties indien nodig\n",
    "    if promo_price != \"N/A\":\n",
    "        promo_price = re.sub(r'Prijs:\\s*€\\s*', '', promo_price)\n",
    "        promo_price = promo_price.strip()  # Verwijder extra spaties rondom de promo prijs\n",
    "\n",
    "    # Extract titel\n",
    "    title_tag = article.find('a', class_='link_root__EqRHd')\n",
    "    title = title_tag.get('title') if title_tag else 'N/A'\n",
    "\n",
    "    # Extract gewicht\n",
    "    weight_span = article.find('span', class_='price_unitSize__Hk6E4')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'N/A'\n",
    "\n",
    "    # Voeg de verkregen data toe aan de lijst\n",
    "    products.append((title, price, promo_price, weight, \"Branded\", \"AH\"))\n",
    "\n",
    "# Verkrijg de huidige timestamp voor wanneer de data werd gescrapet\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Bestandsnaam en sheetnaam\n",
    "file_name = 'choco.xlsx'\n",
    "sheet_name = 'AH_Choco'\n",
    "\n",
    "# Laad of maak een nieuw werkboek aan\n",
    "if os.path.exists(file_name):\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook[sheet_name] if sheet_name in workbook.sheetnames else workbook.create_sheet(sheet_name)\n",
    "else:\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = sheet_name\n",
    "\n",
    "# Schrijf de header als het een nieuw blad is\n",
    "if sheet.max_row == 1:\n",
    "    sheet.append(['Title', 'Price', 'Promo Price', 'Weight', 'Category', 'Store', 'Timestamp'])\n",
    "\n",
    "# Voeg de productdata toe\n",
    "for product in products:\n",
    "    sheet.append([*product, timestamp])\n",
    "\n",
    "# Sla het Excel-bestand op\n",
    "workbook.save(file_name)\n",
    "print(f\"✅ Data succesvol opgeslagen naar {file_name} in blad '{sheet_name}'.\")\n",
    "\n",
    "# Sluit de browser na het scrapen\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49dbe9",
   "metadata": {},
   "source": [
    "### Jumbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455753b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 19 products and saved to choco.xlsx.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Navigate to the Jumbo products page\n",
    "url = \"https://www.jumbo.com/producten/menms/?searchType=keyword&searchTerms=m%26m\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load and accept cookies\n",
    "try:\n",
    "    accept_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.ID, \"onetrust-reject-all-handler\"))\n",
    "    )\n",
    "    accept_button.click()\n",
    "except:\n",
    "    print(\"No accept cookies button found.\")\n",
    "\n",
    "# Wait for products to load\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_all_elements_located((By.CLASS_NAME, \"jum-card\"))\n",
    ")\n",
    "\n",
    "# Load page source into BeautifulSoup\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Extract product data\n",
    "products = []\n",
    "\n",
    "for product_card in soup.find_all(\"div\", class_=\"jum-card\"):\n",
    "    # Extract product title\n",
    "    title_tag = product_card.find(\"a\", class_=\"title-link\")\n",
    "    title = title_tag.text.strip() if title_tag else \"Title not found\"\n",
    "\n",
    "    # Extract promo price\n",
    "    promo_price_div = product_card.find(\"div\", class_=\"promo-price\")\n",
    "    promo_price = (\n",
    "        re.search(r\"[\\d]+[.,][\\d]+\", promo_price_div.text.strip()).group()\n",
    "        if promo_price_div and promo_price_div.text\n",
    "        else \"Promo price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract price\n",
    "    price_whole = product_card.find(\"span\", class_=\"whole\")\n",
    "    price_fractional = product_card.find(\"span\", class_=\"fractional\")\n",
    "    price = (\n",
    "        f\"{price_whole.text.strip()},{price_fractional.text.strip()}\"\n",
    "        if price_whole and price_fractional\n",
    "        else \"Price not found\"\n",
    "    )\n",
    "\n",
    "    # Extract weight\n",
    "    subtitle_div = product_card.find(\"div\", class_=\"subtitle\")\n",
    "    weight_span = subtitle_div.find(\"span\", class_=\"text\") if subtitle_div else None\n",
    "    weight = weight_span.text.strip() if weight_span else \"Weight not found\"\n",
    "\n",
    "    # Append to products list\n",
    "    products.append((title, promo_price, price, weight, \"branded\", \"Jumbo\"))\n",
    "\n",
    "# Write to Excel\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Promo Price\", \"Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Extracted {len(products)} products and saved to {file_name}.\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a2a49",
   "metadata": {},
   "source": [
    "### Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a4dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to choco.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re  # Importing the regular expression module\n",
    "from datetime import datetime  # Importing datetime for timestamp\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Initialize Chrome driver with Service\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url = \"https://www.plus.nl/producten/snoep-koek-chocolade-chips-noten/chocolade/chocoladesnoepjes?merk=M%26M%27S\"\n",
    "driver.get(url)\n",
    "\n",
    "# Click the \"Weigeren\" button to reject cookies on the Plus site\n",
    "\n",
    "# Wait for the \"Weigeren\" button to be clickable\n",
    "accept_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-cookies-refuse')]\")))\n",
    "accept_button.click()\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# List to store the extracted product information\n",
    "products = []\n",
    "\n",
    "# Loop through all product articles\n",
    "for article in soup.find_all('a', id=re.compile(\".*-produt_item_link\")):\n",
    "    # Extract the product title from the title attribute of the anchor tag\n",
    "    title = article.get('title', 'Title not found')\n",
    "\n",
    "    # Extract the price from the price integers and decimals\n",
    "    price_integer = article.find('div', class_='font-bold product-header-price-integer')\n",
    "    price_decimals = article.find('div', class_='font-black product-header-price-decimals')\n",
    "\n",
    "    if price_integer and price_decimals:\n",
    "        price = f\"{price_integer.get_text(strip=True)}{price_decimals.get_text(strip=True)}\"\n",
    "    else:\n",
    "        price = 'Price not found'\n",
    "\n",
    "    # Extract the previous (old) price from the price-previous div\n",
    "    previous_price_span = article.find('div', class_='product-header-price-previous')\n",
    "    if previous_price_span:\n",
    "        # Extract the old price as text\n",
    "        promo_price = previous_price_span.get_text(strip=True)\n",
    "    else:\n",
    "        promo_price = 'Promo price not found'\n",
    "\n",
    "    # Extract the weight from the 'Per 250 g' span\n",
    "    weight_span = article.find('span', class_='OSFillParent')\n",
    "    weight = weight_span.get_text(strip=True) if weight_span else 'Weight not found'\n",
    "\n",
    "    # Store the extracted information as a tuple, including promo price\n",
    "    products.append((title, price, promo_price, weight, \"branded\", \"Plus\"))\n",
    "\n",
    "# Get current timestamp for the data\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d')  # Format: YYYY-MM-DD HH:MM:SS\n",
    "\n",
    "# Write the data to an Excel file\n",
    "file_name = \"choco.xlsx\"\n",
    "\n",
    "try:\n",
    "    # Try loading the existing workbook\n",
    "    workbook = load_workbook(file_name)\n",
    "    sheet = workbook.active\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new workbook and sheet\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    # Write the header row\n",
    "    sheet.append([\"Title\", \"Price\", \"Promo Price\", \"Weight\", \"Brand\", \"Store\", \"Timestamp\"])\n",
    "\n",
    "# Write data to the Excel sheet\n",
    "for product in products:\n",
    "    sheet.append((*product, timestamp))\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save(file_name)\n",
    "\n",
    "print(f\"Data has been successfully saved to {file_name}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
